{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd4e93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nbformat\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "taxonomies = pd.read_csv(\"taxonomies.csv\")\n",
    "\n",
    "conversation_lengths = [2, 3]\n",
    "conversation_weights = [0.5, 0.5]\n",
    "\n",
    "AVAILABLE_INSTRUCTIONS = [\n",
    "    \"change_case:all_caps\",\n",
    "    \"change_case:lowercase\",\n",
    "    \"change_case:alternating\",\n",
    "    \"change_case:first_letter_cap\",\n",
    "    \"change_case:capital_word_frequency\",\n",
    "    \"change_case:lowercase_word_frequency\",\n",
    "    \"change_case:all_caps_target\",\n",
    "    \"change_case:lowercase_target\",\n",
    "    \"change_case:alternating_target\",\n",
    "    \"change_case:first_letter_cap_target\",\n",
    "    \"detectable_content:number_placeholders\",\n",
    "    \"detectable_content:postscript\",\n",
    "    \"detectable_format:json_format\",\n",
    "    \"detectable_format:multiple_sections\",\n",
    "    \"detectable_format:numbered_list\",\n",
    "    \"detectable_format:number_bullet_lists\",\n",
    "    \"detectable_format:title\",\n",
    "    \"keywords:existence\",\n",
    "    \"keywords:frequency\",\n",
    "    \"keywords:forbidden_words\",\n",
    "    \"keywords:letter_frequency\",\n",
    "    \"punctuation:no_comma\",\n",
    "    \"length_constraints:number_characters\",\n",
    "    \"length_constraints:number_words\",\n",
    "    \"length:max_word_count\",\n",
    "    \"startend:start_checker\",\n",
    "    \"startend:end_checker\",\n",
    "    \"startend:wrap_checker\",\n",
    "    \"startend:quotation\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9d37dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenario_with_gpt(l1_taxonomy: str, l1_description: str, l2_taxonomy: str, l2_description: str) -> str:\n",
    "    \"\"\"Generate a scenario using GPT based on taxonomy information.\"\"\"\n",
    "    prompt = f\"\"\"Generate a realistic scenario for a complex instruction following task with the following taxonomy:\n",
    "\n",
    "L1 Taxonomy: {l1_taxonomy}\n",
    "L1 Description: {l1_description}\n",
    "L2 Taxonomy: {l2_taxonomy}\n",
    "L2 Description: {l2_description}\n",
    "\n",
    "The scenario should be specific, realistic, and provide clear context for instruction following. Keep it concise but detailed enough to understand the context.\n",
    "\n",
    "Give one single paragraph after the tag **Scenario:** - and make it clear and concise and mention directly what the user would ask the LLM for.\n",
    "\n",
    "**Scenario:** - \n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates realistic scenarios for tasks that a user would have in a conversation with an AI assistant that involve the provided L1 and L2 taxonomies.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "241ac872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_instructions(l1_taxonomy: str, l2_taxonomy: str, scenario: str) -> List[str]:\n",
    "    \"\"\"Select relevant instructions based on taxonomy and scenario.\"\"\"\n",
    "    prompt = f\"\"\"Given the following taxonomy and scenario, select 6 most relevant instruction IDs from the available list:\n",
    "\n",
    "L1 Taxonomy: {l1_taxonomy}\n",
    "L2 Taxonomy: {l2_taxonomy}\n",
    "Scenario: {scenario}\n",
    "\n",
    "Available instructions: {json.dumps(AVAILABLE_INSTRUCTIONS)}\n",
    "\n",
    "Return only the instruction IDs as a JSON array, no explanation needed.\n",
    "\n",
    "**Instructions:** - \n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that selects relevant instructions for scenarios. Wrap in double quotes and in a json array.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        selected_instructions = json.loads(response.choices[0].message.content.strip())\n",
    "        return selected_instructions[:6]  # Ensure we only get 6 instructions\n",
    "    except:\n",
    "        # Fallback to random selection if parsing fails\n",
    "        return random.sample(AVAILABLE_INSTRUCTIONS, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa0f8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_notebook(row, index):\n",
    "    convo_length = random.choices(conversation_lengths, conversation_weights)[0]\n",
    "\n",
    "    metadata_md = f\"\"\"# Metadata\n",
    "\n",
    "**Domain:** - Complex Instruction Following\n",
    "\n",
    "**L1 Taxonomy:** - {row['L1 Taxonomy']}\n",
    "\n",
    "**L1 Taxonomy Description:** - {row['L1 Taxonomy Description']}\n",
    "\n",
    "**L2 Taxonomy:** - {row['L2 Taxonomy']}\n",
    "\n",
    "**L2 Taxonomy Description:** - {row['L2 Taxonomy Description']}\n",
    "\n",
    "**Conversation Length:** - {convo_length} Turn Tasks\n",
    "\n",
    "{generate_scenario_with_gpt(row['L1 Taxonomy'], row['L1 Taxonomy Description'], row['L2 Taxonomy'], row['L2 Taxonomy Description'])}\n",
    "\n",
    "**Instruction:** - \n",
    "```\n",
    "{select_relevant_instructions(row['L1 Taxonomy'], row['L2 Taxonomy'], generate_scenario_with_gpt(row['L1 Taxonomy'], row['L1 Taxonomy Description'], row['L2 Taxonomy'], row['L2 Taxonomy Description']))}\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    cells = [\n",
    "        nbformat.v4.new_markdown_cell(metadata_md),\n",
    "        nbformat.v4.new_markdown_cell(\"**[user]**\\n\\n// Please begin your conversation from here (Delete this comment post reading)\"),\n",
    "        nbformat.v4.new_markdown_cell(\"\"\"**[turn_metadata]**\n",
    "\n",
    "```\n",
    "{\n",
    "  \"metadata\": [\n",
    "    \"add\"\n",
    "  ],\n",
    "  \"instructions\": [\n",
    "    {\n",
    "      \"instruction_id\": \"\",\n",
    "      \"kwarg1_name\": \"kwarg1_value\",\n",
    "      \"kwarg2_name\": \"kwarg2_value\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "                                      \n",
    "                                      \"\"\"),\n",
    "        nbformat.v4.new_markdown_cell(\"**[assistant]**\"),\n",
    "        nbformat.v4.new_markdown_cell(\"**[user]**\"),\n",
    "        nbformat.v4.new_markdown_cell(\"\"\"**[turn_metadata]**\n",
    "\n",
    "```\n",
    "{\n",
    "  \"metadata\": [\n",
    "    \"add\"\n",
    "  ],\n",
    "  \"instructions\": [\n",
    "    {\n",
    "      \"instruction_id\": \"\",\n",
    "      \"kwarg1_name\": \"kwarg1_value\",\n",
    "      \"kwarg2_name\": \"kwarg2_value\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"),\n",
    "        nbformat.v4.new_markdown_cell(\"**[assistant]**\"),\n",
    "    ]\n",
    "\n",
    "    nb = nbformat.v4.new_notebook(cells=cells)\n",
    "    filename = f\"notebooks-output/{\"multi-turns\" if convo_length > 1 else \"single-turn\"}-,,,{row['L1 Taxonomy']},misc-{index}.ipynb\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        nbformat.write(nb, f)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68f40555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notebooks-output/multi-turns-,,,Rewriting,misc-43.ipynb',\n",
       " 'notebooks-output/multi-turns-,,,Rewriting,misc-42.ipynb',\n",
       " 'notebooks-output/multi-turns-,,,Open-Domain Question Answering,misc-46.ipynb',\n",
       " 'notebooks-output/multi-turns-,,,Open-Domain Question Answering,misc-48.ipynb',\n",
       " 'notebooks-output/multi-turns-,,,Summarization,misc-37.ipynb']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_files = [create_notebook(row, idx) for idx, row in taxonomies.sample().iterrows()]\n",
    "\n",
    "notebook_files[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
